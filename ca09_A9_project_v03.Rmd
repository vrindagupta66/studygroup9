---
title: "Final Group Project: AirBnB analytics"
date: "12 Oct 2021"
author: "Reading Time: About 8 minutes"
output:
  html_document:
    highlight: zenburn
    theme: flatly
    toc: yes
    toc_float: yes
    number_sections: yes
    code_folding: show
---


```{r setup, include=FALSE}
# leave this chunk alone
options(knitr.table.format = "html") 
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
  comment = NA, dpi = 300)
```


```{r load-libraries, echo=FALSE}

library(tidyverse) # the usual stuff: dplyr, readr, and other goodies
library(lubridate) # to handle dates
library(GGally) # for correlation-scatter plot matrix
library(ggfortify) # to produce residual diagnostic plots
library(rsample) # to split dataframe in training- & testing sets
library(janitor) # clean_names()
library(broom) # use broom:augment() to get tidy table with regression output, residuals, etc
library(huxtable) # to get summary table of all models produced
library(kableExtra) # for formatting tables
library(moderndive) # for getting regression tables
library(skimr) # for skim
library(mosaic)
library(leaflet) # for interactive HTML maps
library(tidytext)
library(viridis)
library(vroom)
library(readr)
```

-----

City: Copenhagen 
Variable: the total cost for two people staying 4 nights in an AirBnB in a city.


For our subsequent anaylsis, we chose the city of Copenhangen.

## Loading the data 


```{r load_data, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}

# use cache=TRUE so you dont download the data everytime you knit

listings <- vroom("http://data.insideairbnb.com/denmark/hovedstaden/copenhagen/2021-09-30/data/listings.csv.gz") %>% 
       clean_names()

glimpse(listings)
head(listings)

```

## Description of variables 

You can find a full [data dictionary here](https://docs.google.com/spreadsheets/d/1iWCNJcSutYqpULSQHlNyGInUvHg2BoUGoNRIGa6Szc4/edit#gid=982310896)

- `price` = cost per night 
- `property_type`: type of accommodation (House, Apartment, etc.)
- `room_type`:

  - Entire home/apt (guests have entire place to themselves)
  - Private room (Guests have private room to sleep, all other rooms shared)
  - Shared room (Guests sleep in room shared with others)

- `number_of_reviews`: Total number of reviews for the listing
- `review_scores_rating`: Average review score (0 - 100)
- `longitude` , `latitude`: geographical coordinates to help us locate the listing
- `neighbourhood*`: three variables on a few major neighbourhoods in each city +


# Exploratory Data Analysis (EDA)

In the [R4DS Exploratory Data Analysis chapter](http://r4ds.had.co.nz/exploratory-data-analysis.html){target="_blank"}, the authors state:

> "Your goal during EDA is to develop an understanding of your data. The easiest way to do this is to use questions as tools to guide your investigation... EDA is fundamentally a creative process. And like most creative processes, the key to asking quality questions is to generate a large quantity of questions."


Conduct a thorough EDA. Recall that an EDA involves three things:

* Looking at the raw values.
    * `dplyr::glimpse()`
* Computing summary statistics of the variables of interest, or finding NAs
    * `mosaic::favstats()`
    * `skimr::skim()`
* Creating informative visualizations.
    * `ggplot2::ggplot()`
        * `geom_histogram()` or `geom_density()` for numeric continuous variables
        * `geom_bar()` or `geom_col()` for categorical variables
    * `GGally::ggpairs()` for scaterrlot/correlation matrix
        * Note that you can add transparency to points/density plots in the `aes` call, for example: `aes(colour = gender, alpha = 0.4)`
        
You may wish to have a level 1 header (`#`) for your EDA, then use level 2 sub-headers (`##`) to make sure you cover all three EDA bases. **At a minimum** you should address these questions:

```{r,cache=TRUE}
#variables / columns
glimpse(listings)
```
```{r,cache=TRUE}
#filter for missing / skim data 
listings%>%
  skim() %>%
  filter(n_missing > 0)
```
- How many variables/columns? How many rows/observations?
- Which variables are numbers?
- Which are categorical or *factor* variables (numeric or character variables with variables that have a fixed and known set of possible values?
- What are the correlations between variables? Does each scatterplot support a linear relationship between variables? Do any of the correlations appear to be conditional on the value of a categorical variable?

At this stage, you may also find you want to use `filter`, `mutate`, `arrange`, `select`, or `count`. Let your questions lead you! 

> In all cases, please think about the message your plot is conveying. Don’t just say "This is my X-axis, this is my Y-axis", but rather what’s the **so what** of the plot. Tell some sort of story and speculate about the differences in the patterns in no more than a paragraph.


## Data wrangling


Notice that some of the price data (`price`) is given as a character string, e.g., "$176.00"

Since `price` is a quantitative variable, we need to make sure it is stored as numeric data `num` in the dataframe. To do so, we will first use `readr::parse_number()` which drops any non-numeric characters before or after the first number

```{r, data wrangling}

listings_clean <- listings %>% 
  mutate(price = readr::parse_number(price))
glimpse(listings_clean)

```
Use `typeof(listing$price)` to confirm that `price` is now stored as a number.

```{r}
#check price is a number
typeof(listings_clean$price)
```
   
```{r}
listings_clean%>%
  ggplot(aes(x=price),binwidth=10)+
  geom_histogram()+
  theme_minimal()+
  ggtitle("Histogram of price")
  NULL

listings_clean%>%
  filter(price<=2000) %>%
  ggplot(aes(x=price),binwidth=10) +
  geom_histogram()+
  theme_minimal()+
  ggtitle("Histogram of price less than 2000")
  NULL
```

## Propery types

### Creating the variable prop_type_simplified

```{r, property types}

listings_clean %>%
  group_by(property_type) %>%
  count(sort=TRUE)
```


```{r}
listings_prop <- listings_clean %>%
  mutate(prop_type_simplified = case_when(
    property_type %in% c("Entire rental unit","Private room in residential home", "Entire residential home","Entire condominium (condo)") ~ property_type, 
    TRUE ~ "Other"
  ))
  
```

```{r}
listings_prop %>%
  count(property_type, prop_type_simplified) %>%
  arrange(desc(n))        
```  

**Interpretation:** Hence, we can see that the four most common property types are "Entire rental unit", "Entire condominium (condo)", "Private room in rental unit", "Entire residential home". Together they make up to 87.68% of all property types. We hence moved the remaining c.13% to the category other, which is demonstrated by calling head() on our new dataframe property_df_3.

```{r}
#plot for property_type vs average price 
listings_prop %>%
  group_by(prop_type_simplified)%>%
  summarise(average_price = mean(price)) %>%
  ggplot(aes(x=prop_type_simplified,y=average_price))+
  geom_col()+
   ggtitle("Average Property Price vs Property Type")

```

```{r}

glimpse(listings_clean)

```

```{r}
listings_prop %>%
  select(price,review_scores_rating, review_scores_location, review_scores_location, review_scores_value,
         number_of_reviews, reviews_per_month,
         bedrooms,beds, availability_365) %>%
  ggpairs(alpha=0.5)+
  theme_bw()

```


### Heading 

Airbnb is most commonly used for travel purposes, i.e., as an alternative to traditional hotels. We only want to include  listings in our regression analysis that are intended for travel purposes

- What are the  most common values for the variable `minimum_nights`? 
- Is ther any value among the common values that stands out? 
- What is the likely intended purpose for Airbnb listings with this seemingly unusual value for `minimum_nights`?

Filter the airbnb data so that it only includes observations with `minimum_nights <= 4`


```{r}
#most common value for minimum_nights
listings_prop %>%
  group_by(minimum_nights) %>%
  count(sort=TRUE)
```

```{r}
#filter for data with less than 4 nights 
listings_less_than_4 <- listings_prop %>%
  filter(minimum_nights <= 4)
```

```{r}
#correlation (ggpairs with the filter for less than equal to 4 nights)
listings_less_than_4 %>%
 select(price,review_scores_rating, review_scores_location, review_scores_location, review_scores_value,
         number_of_reviews, reviews_per_month,
         bedrooms,beds, availability_365) %>%
  ggpairs(alpha=0.5)+
  theme_bw()

```


        
# Mapping 

Visualisations of feature distributions and their relations are key to understanding a data set, and they can open up new lines of exploration. While we do not have time to go into all the wonderful geospatial visualisations one can do with R, you can use the following code to start with a map of your city, and overlay all AirBnB coordinates to get an overview of the spatial distribution of AirBnB rentals. For this visualisation we use the `leaflet` package, which includes a variety of tools for interactive maps, so you can easily zoom in-out, click on a point to get the actual AirBnB listing for that specific point, etc.

The following code, having downloaded a dataframe `listings` with all AirbnB listings in Milan, will plot on the map all AirBnBs where `minimum_nights` is less than equal to four (4). You could learn more about `leaflet`, by following [the relevant Datacamp course on mapping with leaflet](https://www.datacamp.com/courses/interactive-maps-with-leaflet-in-r)


```{r, out.width = '80%'}

leaflet(data = filter(listings, minimum_nights <= 4)) %>% 
  addProviderTiles("OpenStreetMap.Mapnik") %>% 
  addCircleMarkers(lng = ~longitude, 
                   lat = ~latitude, 
                   radius = 1, 
                   fillColor = "blue", 
                   fillOpacity = 0.4, 
                   popup = ~listing_url,
                   label = ~property_type)
```

    
# Regression Analysis

Our target variable will be the cost for two people to stay at an Airbnb location for four (4) nights. 

## Data Cleaning 

```{r, data cleaning}

#converting price into a numerical variable 
#regression_df_1 <- listings_clean %>% 
  #mutate(price = readr::parse_number(price))

#creating our output variable "price_4_nights"
regression_df_2 <- regression_df_1 %>%
  filter(accommodates == 2, minimum_nights >= 4, maximum_nights <= 4) %>%
  mutate(price_4_nights = price*4) %>%
  filter(!is.na(price_4_nights)) # removing any missing values , but none seem to exist 

```

## Examining distribution of price_4_nights

```{r, examining distribution of price_4_nights}

regression_df_2 %>%
  ggplot(aes(price_4_nights)) +
  geom_histogram(color="black", fill="grey")+
  theme_bw()+
  geom_density(alpha=0.5) +
  NULL

regression_df_3 <- regression_df_2 %>%
  mutate(log_price_4_nights = log(price_4_nights))

regression_df_3 %>%
  ggplot(aes(log_price_4_nights)) +
  geom_histogram(color="black", fill="pink")+
  theme_bw()+
  geom_density(alpha=0.2) +
  NULL

```
Which variable should you use for the regression model? Why?

**Interpretation:** As we can see from the above 

## Regression Model 1 

Fit a regression model called `model1` with the following explanatory variables: `prop_type_simplified`, `number_of_reviews`, and `review_scores_rating`. 

- Interpret the coefficient `review_scores_rating` in terms of `price_4_nights`.
- Interpret the coefficient of `prop_type_simplified` in terms of `price_4_nights`.


We want to determine if `room_type` is a significant predictor of the cost for 4 nights, given everything else in the model. Fit a regression model called model2 that includes all of the explanatory variables in `model1` plus `room_type`. 

```{r, regression model 1}

glimpse(listings_clean)

#aregression_df_3 %>%
model1 <- lm(price_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating, data = regression_df_2)
  
model2 <- lm(price_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating, data = regression_df_2) 



```



## Further variables/questions to explore on our own

Our dataset has many more variables, so here are some ideas on how you can extend your analysis

1. Are the number of `bathrooms`, `bedrooms`, `beds`, or size of the house (`accomodates`) significant predictors of `price_4_nights`? Or might these be co-linear variables?
1. Do superhosts `(host_is_superhost`) command a pricing premium, after controlling for other variables?
1. Some hosts allow you to immediately book their listing (`instant_bookable == TRUE`), while a non-trivial proportion don't. After controlling for other variables, is `instant_bookable` a significant predictor of `price_4_nights`?
1. For all cities, there are 3 variables that relate to neighbourhoods: `neighbourhood`, `neighbourhood_cleansed`, and `neighbourhood_group_cleansed`. There are typically more than 20 neighbourhoods in each city, and it wouldn't make sense to include them all in your model. Use your city knowledge, or ask someone with city knowledge, and see whether you can group neighbourhoods together so the majority of listings falls in fewer (5-6 max) geographical areas. You would thus need to create a new categorical variabale `neighbourhood_simplified` and determine whether location is a predictor of `price_4_nights`
1. What is the effect of `avalability_30` or `reviews_per_month` on `price_4_nights`, after we control for other variables?


## Diagnostics, collinearity, summary tables

As you keep building your models, it makes sense to:

1. Check the residuals, using `autoplot(model_x)`
1. As you start building models with more explanatory variables, make sure you use `car::vif(model_x)`` to calculate the **Variance Inflation Factor (VIF)** for your predictors and determine whether you have colinear variables. A general guideline is that a VIF larger than 5 or 10 is large, and your model may suffer from collinearity. Remove the variable in question and run your model again without it.



1. Create a summary table, using `huxtable` (https://mfa2022.netlify.app/example/modelling_side_by_side_tables/) that shows which models you worked on, which predictors are significant, the adjusted $R^2$, and the Residual Standard Error.
1. Finally, you must use the best model you came up with for prediction. Suppose you are planning to visit the city you have been assigned to over reading week, and you want to stay in an Airbnb. Find Airbnb's in your destination city that are apartments with a private room, have at least 10 reviews, and an average rating of at least 90. Use your best model to predict the total cost to stay at this Airbnb for 4 nights. Include the appropriate 95% interval with your prediction. Report the point prediction and interval in terms of `price_4_nights`. 
  - if you used a log(price_4_nights) model, make sure you anti-log to convert the value in $. You can read more about [hot to interpret a regression model when some variables are log transformed here](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqhow-do-i-interpret-a-regression-model-when-some-variables-are-log-transformed/)


# Deliverables


- By midnight on Monday 18 Oct 2021, you must upload on Canvas a short presentation (max 4-5 slides) with your findings, as some groups will be asked to present in class. You should present your Exploratory Data Analysis, as well as your best model. In addition, you must upload on Canvas your final report, written  using R Markdown to introduce, frame, and describe your story and findings. You should include the following in the memo:

1. Executive Summary: Based on your best model, indicate the factors that influence `price_4_nights`.
This should be written for an intelligent but non-technical audience. All
other sections can include technical writing.
2. Data Exploration and Feature Selection: Present key elements of the data, including tables and
graphs that help the reader understand the important variables in the dataset. Describe how the
data was cleaned and prepared, including feature selection, transformations, interactions, and
other approaches you considered.
3. Model Selection and Validation: Describe the model fitting and validation process used. State
the model you selected and why they are preferable to other choices.
4. Findings and Recommendations: Interpret the results of the selected model and discuss
additional steps that might improve the analysis
  
  

Remember to follow R Markdown etiquette rules and style; don't have the Rmd output extraneous messages or warnings, include summary tables in nice tables (use `kableExtra`), and remove any placeholder texts from past Rmd templates; in other words, (i.e. I don't want to see stuff I wrote in your final report.)
  
  
# Rubric

Your work will be assessed on a rubric which you can find here


```{r rubric, echo=FALSE, out.width="100%"}
knitr::include_graphics(here::here("images", "rubric.png"), error = FALSE)
```


# Acknowledgements

- The data for this project is from [insideairbnb.com](insideairbnb.com)